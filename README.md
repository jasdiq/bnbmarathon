# ğŸŒ¾ AI Price Prediction Pipeline (BigQuery ML)

This project contains a complete **AI-powered agricultural price prediction pipeline** built using **BigQuery ML**, along with supporting scripts, cleaning workflows, and production-ready components deployed using an ADK agent.

## ğŸ“Œ Key Components

### âœ”ï¸ Data Cleaning  
Scripts to standardize, normalize, and clean raw price datasets.

| Script | Purpose |
|--------|---------|
| `01_clean_data_season1.sql` | Cleans historical farming data |
| `02_clean_latest_data.sql` | Cleans latest daily market prices |
| `03_clean_agg_data.sql` | Cleans aggregated commodity-level pricing data |

---

### âœ”ï¸ Master Table Creation  
| Script | Purpose |
|--------|---------|
| `04_create_master_table.sql` | Joins cleaned tables â†’ creates a single unified training dataset |

---

### âœ”ï¸ Feature Engineering  
| Script | Purpose |
|--------|---------|
| `05_feature_engineering.sql` | Creates lag features, moving averages, seasonal flags, and trend features |

---

### âœ”ï¸ Model Training (BigQuery ML)  
| Script | Purpose |
|--------|---------|
| `06_train_model.sql` | Trains ARIMA_PLUS / time-series model using BigQuery ML |

---

### âœ”ï¸ Prediction  
| Script | Purpose |
|--------|---------|
| `07_predict.sql` | Generates predictions + Sell/Wait recommendation |

---

### âœ”ï¸ Optional Preprocessing (Python)

`preprocessing_notebook.py` â€“ runs inside Vertex AI Notebook to preprocess, visualize, and fix missing values.

---

## ğŸ§  Best Practices & Recommendations

### ğŸ” 1. Data Quality  
- Always check for **NULLs after cleaning & joining**  
- Validate date formats  
- Standardize commodity, district, and market names  

**Missing Value Strategy**  
- Simple: Fill season gaps using historical mean  
- Better: Forward fill (FFILL)  
- Advanced: ML-based imputation

---

### ğŸ”— 2. Joining Logic  
- Ensure consistent keys across all tables  
- Seasonal table joined by year (acceptable simplification)

---

### ğŸ—‚ï¸ 3. Partitioning & Clustering  
- Partition by: `price_date_partition`  
- Cluster by: `district`, `market`, `commodity`  

Benefits:  
- Faster queries  
- Lower BigQuery cost  
- Better performance for window functions

---

### ğŸ¤– 4. Model Training & Evaluation  
- Use date-based train/test split  
- Evaluate with metrics like:  
  - mean_absolute_percentage_error  
  - root_mean_squared_error  
- Tune ARIMA_PLUS hyperparameters

---

## â–¶ï¸ 5. Running the Pipeline  

Run scripts in this order:

```
01_clean_data_season1.sql
02_clean_latest_data.sql
03_clean_agg_data.sql
04_create_master_table.sql
05_feature_engineering.sql
06_train_model.sql
07_predict.sql
```

Run via console or:

```bash
bq query --use_legacy_sql=false < script.sql
```

---

# ğŸ“ Project File Structure

```
adk-agent/
â”œâ”€â”€ cloudbuild.yaml
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ elasticity_test.py
â”œâ”€â”€ pyproject.toml
â”œâ”€â”€ server.py
â”œâ”€â”€ test_gemini.py
â”œâ”€â”€ uv.lock
â”œâ”€â”€ production_adk_agent.egg-info/
â”‚   â”œâ”€â”€ dependency_links.txt
â”‚   â”œâ”€â”€ PKG-INFO
â”‚   â”œâ”€â”€ requires.txt
â”‚   â”œâ”€â”€ SOURCES.txt
â”‚   â””â”€â”€ top_level.txt
â”œâ”€â”€ production_agent/
â”‚   â”œâ”€â”€ agent.py
â”‚   â””â”€â”€ __init__.py
â””â”€â”€ __pycache__/
```

---

# ğŸš€ End-to-End Flow

1. Clean raw farming data  
2. Build master dataset  
3. Engineer features  
4. Train ARIMA+ model  
5. Predict prices  
6. Recommend â€œSell / Waitâ€  
7. Deploy ADK agent  
8. Run load tests on Cloud Run  

---

# ğŸ“¦ Deployment Notes

### Cloud Run  
- Containerized via Dockerfile  
- Auto-scaling tested using elasticity_test.py

### Cloud Build  
- Build & push using cloudbuild.yaml
